{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b44a9c7c-149d-4400-b78c-a486906e74b2",
   "metadata": {},
   "source": [
    "# YOLOv8 Dataset Preprocessing\n",
    "\n",
    "## Dataset\n",
    "\n",
    "> [Teledyne FLIR Free ADAS Thermal Dataset v2](https://adas-dataset-v2.flirconservator.com/#multipartdownloadsection):\n",
    "> The Teledyne FLIR free starter thermal dataset provides fully annotated thermal and visible spectrum frames for development of object detection neural networks. This data was constructed to encourage research on visible + thermal spectrum sensor fusion algorithms (\"RGBT\") in order to advance the safety of autonomous vehicles. A total of 26,442 fully-annotated frames are included with 15 different object classes.\n",
    "\n",
    "\n",
    "> __Baseline Model__: Baseline accuracy for object detection was established using the YOLOX-m neural network designed for 640 X 640 images. Both the RGB and thermal detectors were pre-trained on MSCOCO data ([YOLOX: Exceeding YOLO Series in 2021](https://arxiv.org/abs/2107.08430) and [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)). The base neural networks were trained on the training set data provided in this dataset and tested on the video test data also provided in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53ca7447-583e-4561-8d04-67e82fc66cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25893838-3fb8-4997-abc7-352f4a0f8a74",
   "metadata": {},
   "source": [
    "### Dataset Exploration\n",
    "\n",
    "> Used to directory path and images to be displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac21a968-2851-4048-a79a-50c511c53545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataset\n",
    "images_dataset = glob('./datasets/FLIR_ADAS_v2/video_thermal_test/images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4082581-f2f2-477b-b8f9-f171c54bbbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(images_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2108b71-fcf2-4860-8fee-288c0638e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot multiple random images\n",
    "ran_gen = np.random.default_rng()\n",
    "\n",
    "plt.figure(figsize=(16, 14))\n",
    "plt.suptitle('Thermal Images')\n",
    "for i in range(12):\n",
    "    ax = plt.subplot(4, 4, i+1)\n",
    "    random_index = ran_gen.integers(low=0, high=3748, size=1)\n",
    "    i = random_index[0]\n",
    "    img_loc = images_dataset[i]\n",
    "    img_title = 'video: ' + images_dataset[i][-52:-35]+'\\n'+ 'frame: ' + images_dataset[i][-28:-22]+'\\n'+ 'id: ' + images_dataset[i][-21:-4]\n",
    "    image = plt.imread(img_loc)\n",
    "    plt.imshow(image, cmap=plt.cm.binary)\n",
    "    plt.title(img_title, fontsize='small')\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc4e1f0-ae10-4e18-9342-2a0ea01b72df",
   "metadata": {},
   "source": [
    "### Label Conversion JSON2YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3fadde-b426-45da-b563-fd088781aed3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "YOLOv8 expects all images to be located in an `images` dir and the txt format annotation in a `labels` folder next to it. The dataset was using a dirname of `data` for all images and had COCO JSON annotations. Make sure `data` is renamed to `images` with correct image paths by running `scripts/flir_to_yolo.py` first. Now I am able to run a conversion to create the `labels` dir in the same directory as the `images` dir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b3c2f4-02f9-4dfa-9926-a0f3b8b999f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folders(output_path):\n",
    "    if os.path.exists(output_path):\n",
    "        shutil.rmtree(output_path)\n",
    "    os.makedirs(output_path)\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def convert_bbox_coco2yolo(img_width, img_height, bbox):\n",
    "    \"\"\"\n",
    "    Convert bounding box from COCO  format to YOLO format\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_width : int\n",
    "        width of image\n",
    "    img_height : int\n",
    "        height of image\n",
    "    bbox : list[int]\n",
    "        bounding box annotation in COCO format: \n",
    "        [top left x position, top left y position, width, height]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[float]\n",
    "        bounding box annotation in YOLO format: \n",
    "        [x_center_rel, y_center_rel, width_rel, height_rel]\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOLO bounding box format: [x_center, y_center, width, height]\n",
    "    # (float values relative to width and height of image)\n",
    "    x_tl, y_tl, w, h = bbox\n",
    "\n",
    "    dw = 1.0 / img_width\n",
    "    dh = 1.0 / img_height\n",
    "\n",
    "    x_center = x_tl + w / 2.0\n",
    "    y_center = y_tl + h / 2.0\n",
    "\n",
    "    x = x_center * dw\n",
    "    y = y_center * dh\n",
    "    w = w * dw\n",
    "    h = h * dh\n",
    "\n",
    "    return [x, y, w, h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "346a15a6-c3a0-4de7-a5d3-4c448cb1bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coco_json_to_yolo_txt(output_path, json_file):\n",
    "\n",
    "    path = make_folders(output_path)\n",
    "\n",
    "    with open(json_file) as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    # write _darknet.labels, which holds names of all classes (one class per line)\n",
    "    label_file = os.path.join(output_path, \"_darknet.labels\")\n",
    "    with open(label_file, \"w\") as f:\n",
    "        for category in tqdm(json_data[\"categories\"], desc=\"Categories\"):\n",
    "            category_name = category[\"name\"]\n",
    "            f.write(f\"{category_name}\\n\")\n",
    "\n",
    "    for image in tqdm(json_data[\"images\"], desc=\"Annotation txt for each iamge\"):\n",
    "        img_id = image[\"id\"]\n",
    "        img_name = image[\"file_name\"]\n",
    "        img_width = image[\"width\"]\n",
    "        img_height = image[\"height\"]\n",
    "\n",
    "        anno_in_image = [anno for anno in json_data[\"annotations\"] if anno[\"image_id\"] == img_id]\n",
    "        anno_txt = os.path.join(output_path, img_name.split(\".\")[0] + \".txt\")\n",
    "        with open(anno_txt, \"w\") as f:\n",
    "            for anno in anno_in_image:\n",
    "                category = anno[\"category_id\"]\n",
    "                bbox_COCO = anno[\"bbox\"]\n",
    "                x, y, w, h = convert_bbox_coco2yolo(img_width, img_height, bbox_COCO)\n",
    "                f.write(f\"{category} {x:.6f} {y:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "\n",
    "    print(\"Converting COCO Json to YOLO txt finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b35011a-7950-42f4-be35-687fdd6bd53e",
   "metadata": {},
   "source": [
    "#### Create labels for all image datasets from the parent repo\n",
    "\n",
    "Pass in the annotations.json and locations of labels to be generated. The `labels` dir will need to be placed in the same directory where the `images` dir is stored. Yolo methods depend on both `labels` and `images` to be in the same directory for training, validation, and testing. \n",
    "\n",
    "Either run the Multi Dataset Conversion or the Single Dataset conversion.\n",
    "* `config` is the default directory for dataset .jsons. However, this will need to be changed if `filtered` was used to narrow down a dataset to specific categories. The dataset dir will remain the same, but replace the `config` dir with filtered one if used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "926eb704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset path for where the image datasets are stored\n",
    "# Config directory where the coco formatted .json files are stored\n",
    "DATASET_DIR = './datasets/FLIR_ADAS_v2/'\n",
    "CONFIG_DIR = './config/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba8d9e8",
   "metadata": {},
   "source": [
    "#### Multi Dataset Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b929ab-e7b0-4030-a19e-c1d1e2f7a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in os.scandir(DATASET_DIR):\n",
    "    label_dir = DATASET_DIR + dir.name + '/labels'\n",
    "    config_dir = CONFIG_DIR + dir.name + '_coco.json'\n",
    "    convert_coco_json_to_yolo_txt(label_dir, config_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701dda62",
   "metadata": {},
   "source": [
    "#### Single Dataset Conversion\n",
    "\n",
    "For processing datasets individually. Run if multi-dataset conversion is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_thermal_train\n",
    "convert_coco_json_to_yolo_txt(\"./datasets/FLIR_ADAS_v2/images_thermal_train/labels\", \"./config/images_thermal_train_coco.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b50e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_thermal_val\n",
    "convert_coco_json_to_yolo_txt(\"./datasets/FLIR_ADAS_v2/images_thermal_val/labels\", \"./config/images_thermal_val_coco.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b90638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_thermal_test\n",
    "convert_coco_json_to_yolo_txt(\"./datasets/FLIR_ADAS_v2/video_thermal_test/labels\", \"./config/video_thermal_test_coco.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0e5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_rgb_train\n",
    "convert_coco_json_to_yolo_txt(\"./datasets/FLIR_ADAS_v2/images_rgb_train/labels\", \"./config/images_rgb_train_coco.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d156b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_rgb_val\n",
    "convert_coco_json_to_yolo_txt(\"./datasets/FLIR_ADAS_v2/images_rgb_val/labels\", \"./config/images_rgb_train_coco.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ddb98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_rgb_test\n",
    "convert_coco_json_to_yolo_txt(\"./datasets/FLIR_ADAS_v2/video_rgb_test/labels\", \"./config/video_rgb_test_coco.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d63999c-1bff-4088-935d-a2ea46834918",
   "metadata": {},
   "source": [
    "### Dataset Configuration\n",
    "\n",
    "The `coco.yaml` file that came with the dataset contained all 80 COCO classes - I removed all classes that were not part of the annotation and assigned new `category_id`'s from `0`-`15` for the 16 categories. If you want to use the configuration files below to train your YOLO model you need to replace the annotations accordingly - check the `./config` folder.\n",
    "\n",
    "If a filtered .json is used, the value should match the number of categories. \n",
    "\n",
    "\n",
    "* `config/data_thermal.yaml`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf23e0-7d4a-4b0a-b27a-cfeca59ac1c1",
   "metadata": {},
   "source": [
    "```yaml\n",
    "train: ../images_thermal_train/images\n",
    "val: ../images_thermal_val/images\n",
    "test: ../video_thermal_test/images\n",
    "\n",
    "nc: 16\n",
    "names: [\n",
    "  'person',\n",
    "  'bike',\n",
    "  'car',\n",
    "  'motor',\n",
    "  'bus',\n",
    "  'train',\n",
    "  'truck',\n",
    "  'light',\n",
    "  'hydrant',\n",
    "  'sign',\n",
    "  'dog',\n",
    "  'deer',\n",
    "  'skateboard',\n",
    "  'stroller',\n",
    "  'scooter',\n",
    "  'other vehicle'\n",
    "  ]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d549488d-b4ed-433a-ac11-2e767490ac31",
   "metadata": {},
   "source": [
    "* `config/data_rgb.yaml`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ef9df5-f352-4231-88a9-291b6af33bf8",
   "metadata": {},
   "source": [
    "```yaml\n",
    "train: /opt/app/datasets/images_rgb_train/images\n",
    "val: /opt/app/datasets/images_rgb_val/images\n",
    "test: /opt/app/datasets/video_rgb_test/images\n",
    "\n",
    "nc: 16\n",
    "names: [\n",
    "  'person',\n",
    "  'bike',\n",
    "  'car',\n",
    "  'motor',\n",
    "  'bus',\n",
    "  'train',\n",
    "  'truck',\n",
    "  'light',\n",
    "  'hydrant',\n",
    "  'sign',\n",
    "  'dog',\n",
    "  'deer',\n",
    "  'skateboard',\n",
    "  'stroller',\n",
    "  'scooter',\n",
    "  'other vehicle'\n",
    "  ]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a41dcc0",
   "metadata": {},
   "source": [
    "#### Multi Annotation Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db3a65e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config directory where the coco formatted .json files are stored\n",
    "CONFIG_DIR = './config_person/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f302a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(CONFIG_DIR):\n",
    "    if file.endswith('.json'):\n",
    "        f_config = open(CONFIG_DIR + file) # => './datasets/images_thermal_val/coco.json'\n",
    "        # returns JSON object as a dictionary\n",
    "        config_val = json.load(f_config)\n",
    "        # closing files\n",
    "        f_config.close()\n",
    "\n",
    "        categories = []\n",
    "\n",
    "        for detection in config_val['annotations']:\n",
    "            categories.append(detection['category_id'])\n",
    "\n",
    "        print(\"{}: {}\".format(file, np.unique(categories)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065ca714",
   "metadata": {},
   "source": [
    "#### Single Annotation Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f928848-4c49-436a-ad34-756acb95dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_rgb = open('./config/images_rgb_val_coco.json') # =>'./datasets/images_rgb_val/coco.json'\n",
    "f_thermal = open('./config/images_thermal_val_coco.json') # => './datasets/images_thermal_val/coco.json'\n",
    "# returns JSON object as a dictionary\n",
    "data_rgb_val = json.load(f_rgb)\n",
    "data_thermal_val = json.load(f_thermal)\n",
    "# closing files\n",
    "f_rgb.close()\n",
    "f_thermal.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a40922a-6c49-4e42-9734-9dd16d26643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_rgb = open('./config/images_rgb_train_coco.json') # => './datasets/images_rgb_train/coco.json'\n",
    "f_thermal = open('./config/images_thermal_train_coco.json') # => './datasets/images_thermal_train/coco.json'\n",
    "# returns JSON object as a dictionary\n",
    "data_rgb_train = json.load(f_rgb)\n",
    "data_thermal_train = json.load(f_thermal)\n",
    "# closing files\n",
    "f_rgb.close()\n",
    "f_thermal.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac549b67-7eef-44af-b8aa-58e6f88119ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_rgb = open('./config/video_rgb_test_coco.json') # => './datasets/video_rgb_test/coco.json'\n",
    "f_thermal = open('./config/video_thermal_test_coco.json') # => './datasets/video_thermal_test/coco.json'\n",
    "# returns JSON object as a dictionary\n",
    "data_rgb_test = json.load(f_rgb)\n",
    "data_thermal_test = json.load(f_thermal)\n",
    "# closing files\n",
    "f_rgb.close()\n",
    "f_thermal.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a4def2-cf00-4f9f-b461-81aba0b96bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating through the json list - check that all annotations are between 0 and 15\n",
    "\n",
    "categories = []\n",
    "\n",
    "for detection in data_rgb_val['annotations']:\n",
    "    categories.append(detection['category_id'])\n",
    "\n",
    "print(np.unique(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa168b-ceaa-4281-a01b-863b544a6607",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "\n",
    "for detection in data_thermal_val['annotations']:\n",
    "    categories.append(detection['category_id'])\n",
    "\n",
    "print(np.unique(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba01b1f8-ccd7-4aab-9c0f-465e5bb62d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "\n",
    "for detection in data_rgb_train['annotations']:\n",
    "    categories.append(detection['category_id'])\n",
    "\n",
    "print(np.unique(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c9744a-8341-415f-8120-8f55e390d0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "\n",
    "for detection in data_thermal_train['annotations']:\n",
    "    categories.append(detection['category_id'])\n",
    "\n",
    "print(np.unique(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b26820-e115-4e68-8dcb-7fb231f5e741",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "\n",
    "for detection in data_rgb_test['annotations']:\n",
    "    categories.append(detection['category_id'])\n",
    "\n",
    "print(np.unique(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fb361d-91b8-4d3c-9ddc-df0bb43d6a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "\n",
    "for detection in data_thermal_test['annotations']:\n",
    "    categories.append(detection['category_id'])\n",
    "\n",
    "print(np.unique(categories))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
