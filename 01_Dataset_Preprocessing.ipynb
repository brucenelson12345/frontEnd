{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b44a9c7c-149d-4400-b78c-a486906e74b2",
   "metadata": {},
   "source": [
    "# YOLOv8 Nightshift\n",
    "\n",
    "## Dataset\n",
    "\n",
    "> [Teledyne FLIR Free ADAS Thermal Dataset v2](https://adas-dataset-v2.flirconservator.com/#multipartdownloadsection):\n",
    "> The Teledyne FLIR free starter thermal dataset provides fully annotated thermal and visible spectrum frames for development of object detection neural networks. This data was constructed to encourage research on visible + thermal spectrum sensor fusion algorithms (\"RGBT\") in order to advance the safety of autonomous vehicles. A total of 26,442 fully-annotated frames are included with 15 different object classes.\n",
    "\n",
    "\n",
    "> __Baseline Model__: Baseline accuracy for object detection was established using the YOLOX-m neural network designed for 640 X 640 images. Both the RGB and thermal detectors were pre-trained on MSCOCO data ([YOLOX: Exceeding YOLO Series in 2021](https://arxiv.org/abs/2107.08430) and [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)). The base neural networks were trained on the training set data provided in this dataset and tested on the video test data also provided in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53ca7447-583e-4561-8d04-67e82fc66cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25893838-3fb8-4997-abc7-352f4a0f8a74",
   "metadata": {},
   "source": [
    "### Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac21a968-2851-4048-a79a-50c511c53545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataset\n",
    "images_themal = glob('./datasets/video_thermal_test/images/*.jpg')\n",
    "images_rgb = glob('./datasets/video_rgb_test/images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4082581-f2f2-477b-b8f9-f171c54bbbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(images_themal), len(images_rgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2108b71-fcf2-4860-8fee-288c0638e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot multiple random thermal images\n",
    "ran_gen = np.random.default_rng()\n",
    "\n",
    "plt.figure(figsize=(16, 14))\n",
    "plt.suptitle('Thermal Images')\n",
    "for i in range(12):\n",
    "    ax = plt.subplot(4, 4, i+1)\n",
    "    random_index = ran_gen.integers(low=0, high=3748, size=1)\n",
    "    i = random_index[0]\n",
    "    img_loc = images_themal[i]\n",
    "    img_title = 'video: ' + images_themal[i][-52:-35]+'\\n'+ 'frame: ' + images_themal[i][-28:-22]+'\\n'+ 'id: ' + images_themal[i][-21:-4]\n",
    "    image = plt.imread(img_loc)\n",
    "    plt.imshow(image, cmap=plt.cm.binary)\n",
    "    plt.title(img_title, fontsize='small')\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a4beb7-02d9-4f05-9e86-405447b52030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot multiple random rgb images\n",
    "ran_gen = np.random.default_rng()\n",
    "\n",
    "plt.figure(figsize=(16, 14))\n",
    "plt.suptitle('RGB Images')\n",
    "for i in range(12):\n",
    "    ax = plt.subplot(4, 4, i+1)\n",
    "    random_index = ran_gen.integers(low=0, high=3748, size=1)\n",
    "    i = random_index[0]\n",
    "    img_loc = images_rgb[i]\n",
    "    img_title = 'video: ' + images_rgb[i][-52:-35]+'\\n'+ 'frame: ' + images_rgb[i][-28:-22]+'\\n'+ 'id: ' + images_rgb[i][-21:-4]\n",
    "    image = plt.imread(img_loc)\n",
    "    plt.imshow(image, cmap=plt.cm.binary)\n",
    "    plt.title(img_title, fontsize='small')\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc4e1f0-ae10-4e18-9342-2a0ea01b72df",
   "metadata": {},
   "source": [
    "### Label Conversion JSON2YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3fadde-b426-45da-b563-fd088781aed3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "* `\"file_name\": \"data/video-BzZspxAweF8AnKhWK-frame-000745-SSCRtAHcFjphNPczJ.jpg\",` -> `\"file_name\": \"video-BzZspxAweF8AnKhWK-frame-000745-SSCRtAHcFjphNPczJ.jpg\",`\n",
    "\n",
    "YOLOv8 expects all images to be located in an `images` dir and the txt format annotation in a `labels` folder next to it. The dataset was using a dirname of `data` for all images and had COCO JSON annotations. I renamed the folder, created the missing one and removed the \"data/\" from all the filenames in the JSON file. Now I am able to run a conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b3c2f4-02f9-4dfa-9926-a0f3b8b999f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folders(output_path):\n",
    "    if os.path.exists(output_path):\n",
    "        shutil.rmtree(output_path)\n",
    "    os.makedirs(output_path)\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def convert_bbox_coco2yolo(img_width, img_height, bbox):\n",
    "    \"\"\"\n",
    "    Convert bounding box from COCO  format to YOLO format\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_width : int\n",
    "        width of image\n",
    "    img_height : int\n",
    "        height of image\n",
    "    bbox : list[int]\n",
    "        bounding box annotation in COCO format: \n",
    "        [top left x position, top left y position, width, height]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[float]\n",
    "        bounding box annotation in YOLO format: \n",
    "        [x_center_rel, y_center_rel, width_rel, height_rel]\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOLO bounding box format: [x_center, y_center, width, height]\n",
    "    # (float values relative to width and height of image)\n",
    "    x_tl, y_tl, w, h = bbox\n",
    "\n",
    "    dw = 1.0 / img_width\n",
    "    dh = 1.0 / img_height\n",
    "\n",
    "    x_center = x_tl + w / 2.0\n",
    "    y_center = y_tl + h / 2.0\n",
    "\n",
    "    x = x_center * dw\n",
    "    y = y_center * dh\n",
    "    w = w * dw\n",
    "    h = h * dh\n",
    "\n",
    "    return [x, y, w, h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "346a15a6-c3a0-4de7-a5d3-4c448cb1bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coco_json_to_yolo_txt(output_path, json_file):\n",
    "\n",
    "    path = make_folders(output_path)\n",
    "\n",
    "    with open(json_file) as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    # write _darknet.labels, which holds names of all classes (one class per line)\n",
    "    label_file = os.path.join(output_path, \"_darknet.labels\")\n",
    "    with open(label_file, \"w\") as f:\n",
    "        for category in tqdm(json_data[\"categories\"], desc=\"Categories\"):\n",
    "            category_name = category[\"name\"]\n",
    "            f.write(f\"{category_name}\\n\")\n",
    "\n",
    "    for image in tqdm(json_data[\"images\"], desc=\"Annotation txt for each iamge\"):\n",
    "        img_id = image[\"id\"]\n",
    "        img_name = image[\"file_name\"]\n",
    "        img_width = image[\"width\"]\n",
    "        img_height = image[\"height\"]\n",
    "\n",
    "        anno_in_image = [anno for anno in json_data[\"annotations\"] if anno[\"image_id\"] == img_id]\n",
    "        anno_txt = os.path.join(output_path, img_name.split(\".\")[0] + \".txt\")\n",
    "        with open(anno_txt, \"w\") as f:\n",
    "            for anno in anno_in_image:\n",
    "                category = anno[\"category_id\"]\n",
    "                bbox_COCO = anno[\"bbox\"]\n",
    "                x, y, w, h = convert_bbox_coco2yolo(img_width, img_height, bbox_COCO)\n",
    "                f.write(f\"{category} {x:.6f} {y:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "\n",
    "    print(\"Converting COCO Json to YOLO txt finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b35011a-7950-42f4-be35-687fdd6bd53e",
   "metadata": {},
   "source": [
    "#### Video RGB Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "68b929ab-e7b0-4030-a19e-c1d1e2f7a9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categories: 100%|██████████| 16/16 [00:00<00:00, 459649.75it/s]\n",
      "Annotation txt for each iamge: 100%|██████████| 3749/3749 [00:37<00:00, 98.75it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting COCO Json to YOLO txt finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#convert_coco_json_to_yolo_txt(\"./datasets/video_rgb_test/labels\", \"./datasets/video_rgb_test/coco.json\")\n",
    "convert_coco_json_to_yolo_txt(\"./datasets/video_rgb_test/labels\", \"./config/video_rgb_test_coco.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a885f94e-a64b-468b-a404-a874ad12e022",
   "metadata": {},
   "source": [
    "#### Video Thermal Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7099c705-79a6-4ce8-bd6b-e72666db2e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categories: 100%|██████████| 16/16 [00:00<00:00, 573580.03it/s]\n",
      "Annotation txt for each iamge: 100%|██████████| 3749/3749 [00:15<00:00, 247.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting COCO Json to YOLO txt finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#convert_coco_json_to_yolo_txt(\"./datasets/video_thermal_test/labels\", \"./datasets/video_thermal_test/coco.json\")\n",
    "convert_coco_json_to_yolo_txt(\"./datasets/video_rgb_test/labels\", \"./config/video_thermal_test_coco.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533347ec-6415-4931-9c0c-9464053feda0",
   "metadata": {},
   "source": [
    "#### Images RGB Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f802bc6-ff4f-42e0-aec0-ad9a6a3f6c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categories: 100%|██████████| 16/16 [00:00<00:00, 432960.41it/s]\n",
      "Annotation txt for each iamge: 100%|██████████| 10318/10318 [03:41<00:00, 46.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting COCO Json to YOLO txt finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#convert_coco_json_to_yolo_txt(\"./datasets/images_rgb_train/labels\", \"./datasets/images_rgb_train/coco.json\")\n",
    "convert_coco_json_to_yolo_txt(\"./datasets/images_rgb_train/labels\", \"./config/images_rgb_train_coco.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a3f958-0a6e-4fc5-925a-3ecc36f9a2a7",
   "metadata": {},
   "source": [
    "#### Images Thermal Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e1b41beb-abed-4b7f-be8f-d119d5aa9ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categories: 100%|██████████| 16/16 [00:00<00:00, 430185.03it/s]\n",
      "Annotation txt for each iamge: 100%|██████████| 10742/10742 [03:28<00:00, 51.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting COCO Json to YOLO txt finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#convert_coco_json_to_yolo_txt(\"./datasets/images_thermal_train/labels\", \"./datasets/images_thermal_train/coco.json\")\n",
    "convert_coco_json_to_yolo_txt(\"./datasets/images_thermal_train/labels\", \"./config/images_thermal_train_coco.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6036906-afd1-486c-a18a-6178c4c18d8e",
   "metadata": {},
   "source": [
    "#### Images RGB Val Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b28fbe53-468a-4a4f-8d30-3f937b699b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categories: 100%|██████████| 16/16 [00:00<00:00, 615677.65it/s]\n",
      "Annotation txt for each iamge: 100%|██████████| 1085/1085 [00:00<00:00, 2243.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting COCO Json to YOLO txt finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#convert_coco_json_to_yolo_txt(\"./datasets/images_rgb_val/labels\", \"./datasets/images_rgb_val/coco.json\")\n",
    "convert_coco_json_to_yolo_txt(\"./datasets/images_rgb_val/labels\", \"./config/images_rgb_val_coco.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e01b1ae-79be-4de8-ad9f-b1e82645a78c",
   "metadata": {},
   "source": [
    "#### Images Thermal Val Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3581aecf-b146-4541-8414-077d8181fb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categories: 100%|██████████| 16/16 [00:00<00:00, 416825.24it/s]\n",
      "Annotation txt for each iamge: 100%|██████████| 1144/1144 [00:00<00:00, 2276.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting COCO Json to YOLO txt finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#convert_coco_json_to_yolo_txt(\"./datasets/images_thermal_val/labels\", \"./datasets/images_thermal_val/coco.json\")\n",
    "convert_coco_json_to_yolo_txt(\"./datasets/images_thermal_val/labels\", \"./config/images_thermal_val_coco.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d63999c-1bff-4088-935d-a2ea46834918",
   "metadata": {},
   "source": [
    "### Dataset Configuration\n",
    "\n",
    "The `coco.yaml` file that came with the dataset contained all 80 COCO classes - I removed all classes that were not part of the annotation and assigned new `category_id`'s from `0`-`15` for the 16 categories. If you want to use the configuration files below to train your YOLO model you need to replace the annotations accordingly - check the `./config` folder.\n",
    "\n",
    "\n",
    "* `config/data_thermal.yaml`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf23e0-7d4a-4b0a-b27a-cfeca59ac1c1",
   "metadata": {},
   "source": [
    "```yaml\n",
    "train: ../images_thermal_train/images\n",
    "val: ../images_thermal_val/images\n",
    "test: ../video_thermal_test/images\n",
    "\n",
    "nc: 16\n",
    "names: [\n",
    "  'person',\n",
    "  'bike',\n",
    "  'car',\n",
    "  'motor',\n",
    "  'bus',\n",
    "  'train',\n",
    "  'truck',\n",
    "  'light',\n",
    "  'hydrant',\n",
    "  'sign',\n",
    "  'dog',\n",
    "  'deer',\n",
    "  'skateboard',\n",
    "  'stroller',\n",
    "  'scooter',\n",
    "  'other vehicle'\n",
    "  ]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d549488d-b4ed-433a-ac11-2e767490ac31",
   "metadata": {},
   "source": [
    "* `config/data_rgb.yaml`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ef9df5-f352-4231-88a9-291b6af33bf8",
   "metadata": {},
   "source": [
    "```yaml\n",
    "train: /opt/app/datasets/images_rgb_train/images\n",
    "val: /opt/app/datasets/images_rgb_val/images\n",
    "test: /opt/app/datasets/video_rgb_test/images\n",
    "\n",
    "nc: 16\n",
    "names: [\n",
    "  'person',\n",
    "  'bike',\n",
    "  'car',\n",
    "  'motor',\n",
    "  'bus',\n",
    "  'train',\n",
    "  'truck',\n",
    "  'light',\n",
    "  'hydrant',\n",
    "  'sign',\n",
    "  'dog',\n",
    "  'deer',\n",
    "  'skateboard',\n",
    "  'stroller',\n",
    "  'scooter',\n",
    "  'other vehicle'\n",
    "  ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3f928848-4c49-436a-ad34-756acb95dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_rgb = open('./config/images_rgb_val_coco.json') # =>'./datasets/images_rgb_val/coco.json'\n",
    "f_thermal = open('./config/images_thermal_val_coco.json') # => './datasets/images_thermal_val/coco.json'\n",
    "# returns JSON object as a dictionary\n",
    "data_rgb_val = json.load(f_rgb)\n",
    "data_thermal_val = json.load(f_thermal)\n",
    "# closing files\n",
    "f_rgb.close()\n",
    "f_thermal.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6a40922a-6c49-4e42-9734-9dd16d26643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_rgb = open('./config/images_rgb_train_coco.json') # => './datasets/images_rgb_train/coco.json'\n",
    "f_thermal = open('./config/images_thermal_train_coco.json') # => './datasets/images_thermal_train/coco.json'\n",
    "# returns JSON object as a dictionary\n",
    "data_rgb_train = json.load(f_rgb)\n",
    "data_thermal_train = json.load(f_thermal)\n",
    "# closing files\n",
    "f_rgb.close()\n",
    "f_thermal.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ac549b67-7eef-44af-b8aa-58e6f88119ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_rgb = open('./config/video_rgb_test_coco.json') # => './datasets/video_rgb_test/coco.json'\n",
    "f_thermal = open('./config/video_thermal_test_coco.json') # => './datasets/video_thermal_test/coco.json'\n",
    "# returns JSON object as a dictionary\n",
    "data_rgb_test = json.load(f_rgb)\n",
    "data_thermal_test = json.load(f_thermal)\n",
    "# closing files\n",
    "f_rgb.close()\n",
    "f_thermal.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "32a4def2-cf00-4f9f-b461-81aba0b96bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  5  6  8  9 12 13 15]\n"
     ]
    }
   ],
   "source": [
    "# Iterating through the json list - check that all annotations are between 0 and 15\n",
    "\n",
    "categories = []\n",
    "\n",
    "for detection in data_rgb_val['annotations']:\n",
    "    categories.append(detection['category_id'])\n",
    "\n",
    "print(np.unique(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1dfa168b-ceaa-4281-a01b-863b544a6607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  5  6  8  9 12 13 15]\n"
     ]
    }
   ],
   "source": [
    "categories = []\n",
    "\n",
    "for detection in data_thermal_val['annotations']:\n",
    "    categories.append(detection['category_id'])\n",
    "\n",
    "print(np.unique(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ba01b1f8-ccd7-4aab-9c0f-465e5bb62d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  5  6  8  9 12 13 14 15]\n"
     ]
    }
   ],
   "source": [
    "categories = []\n",
    "\n",
    "for detection in data_rgb_train['annotations']:\n",
    "    categories.append(detection['category_id'])\n",
    "\n",
    "print(np.unique(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "83c9744a-8341-415f-8120-8f55e390d0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  5  6  8  9 10 11 12 13 14 15]\n"
     ]
    }
   ],
   "source": [
    "categories = []\n",
    "\n",
    "for detection in data_thermal_train['annotations']:\n",
    "    categories.append(detection['category_id'])\n",
    "\n",
    "print(np.unique(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d1b26820-e115-4e68-8dcb-7fb231f5e741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  6  7  8  9 10 15]\n"
     ]
    }
   ],
   "source": [
    "categories = []\n",
    "\n",
    "for detection in data_rgb_test['annotations']:\n",
    "    categories.append(detection['category_id'])\n",
    "\n",
    "print(np.unique(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00fb361d-91b8-4d3c-9ddc-df0bb43d6a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  6  8  9 10 15]\n"
     ]
    }
   ],
   "source": [
    "categories = []\n",
    "\n",
    "for detection in data_thermal_test['annotations']:\n",
    "    categories.append(detection['category_id'])\n",
    "\n",
    "print(np.unique(categories))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
